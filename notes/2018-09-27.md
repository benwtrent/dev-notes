Back from a [fun meetup in Dallas](https://www.meetup.com/DFW-Data-Science/events/254275669/) good discussion with folks around ML. 

A couple of the data scientists in the crowd was asking about the ability to utilize their own algorithms for Elastic Stack's ML anomaly detection, or at least being able to copy the model and use it elsewhere. 

## Today

* Opened a PR for a simple Rollup API bug: https://github.com/elastic/elasticsearch/pull/34115
* Started discussion around and working on https://github.com/elastic/elasticsearch/issues/31999
   * This is turning into quiet the monster. Aggregations are powerful, flexible, and consequently, difficult to compare between two disparate systems. 
   * I am running into a wall now trying to determin if the DatafeedConfig and the RollupJobConfig share similar aggregations so we don't supply bad data. 
   * This is an obvious win for our users as the ability to query against rolled up data without the loss of entropy is great. The pain is worth the price.
* Talked about auto generating API documentation for Elasticsearch + Features (ML, Watcher, etc.). This pretty big undertaking. There are only two options that I know of.
   * Get a parser that can build out JSON Schema's that adhere to the OpenAPI 3.0 spec from our XContent `PARSER`
       * This has the benefit of capturing changes as they are added/removed from the provided end user content
   * Somehow utilize the High Level Rest Client(HLRC) POJOs to generate the schemas
       * This relies on dev work to make sure the HLRC Pojos match up and are simpler to parse than our internal Response/Request objects. So far, that is the case, but I could definitely see this getting out of hand if we don't stay on top of it. 
   * NOTE: this is not just a win for our documentation, but also for our Dev console auto-complete in Kibana (as they use JSON Schemas matched up against endpoints).
